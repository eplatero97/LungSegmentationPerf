{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 11:20:38,007 - mmseg - INFO - Multi-processing start method is `None`\n",
      "2022-11-19 11:20:38,008 - mmseg - INFO - OpenCV num_threads is `8\n",
      "2022-11-19 11:20:38,171 - mmcv - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'open-mmlab://resnet50_v1c'}\n",
      "2022-11-19 11:20:38,171 - mmcv - INFO - load model from: open-mmlab://resnet50_v1c\n",
      "2022-11-19 11:20:38,172 - mmcv - INFO - load checkpoint from openmmlab path: open-mmlab://resnet50_v1c\n",
      "2022-11-19 11:20:38,245 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
      "size mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([64, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
      "size mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n",
      "size mismatch for layer2.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1, 1]).\n",
      "size mismatch for layer2.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for layer2.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for layer2.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "size mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([128, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "size mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n",
      "size mismatch for layer3.0.downsample.0.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 128, 1, 1]).\n",
      "size mismatch for layer3.0.downsample.1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for layer3.0.downsample.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for layer3.0.downsample.1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "size mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([256, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
      "size mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 3, 3]).\n",
      "size mismatch for layer4.0.downsample.0.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n",
      "size mismatch for layer4.0.downsample.1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for layer4.0.downsample.1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for layer4.0.downsample.1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "size mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([512, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
      "unexpected key in source state_dict: stem.0.weight, stem.1.weight, stem.1.bias, stem.1.running_mean, stem.1.running_var, stem.1.num_batches_tracked, stem.3.weight, stem.4.weight, stem.4.bias, stem.4.running_mean, stem.4.running_var, stem.4.num_batches_tracked, stem.6.weight, stem.7.weight, stem.7.bias, stem.7.running_mean, stem.7.running_var, stem.7.num_batches_tracked, fc.weight, fc.bias, layer1.2.conv1.weight, layer1.2.bn1.weight, layer1.2.bn1.bias, layer1.2.bn1.running_mean, layer1.2.bn1.running_var, layer1.2.bn1.num_batches_tracked, layer1.2.conv2.weight, layer1.2.bn2.weight, layer1.2.bn2.bias, layer1.2.bn2.running_mean, layer1.2.bn2.running_var, layer1.2.bn2.num_batches_tracked, layer1.2.conv3.weight, layer1.2.bn3.weight, layer1.2.bn3.bias, layer1.2.bn3.running_mean, layer1.2.bn3.running_var, layer1.2.bn3.num_batches_tracked, layer1.0.conv3.weight, layer1.0.bn3.weight, layer1.0.bn3.bias, layer1.0.bn3.running_mean, layer1.0.bn3.running_var, layer1.0.bn3.num_batches_tracked, layer1.0.downsample.0.weight, layer1.0.downsample.1.weight, layer1.0.downsample.1.bias, layer1.0.downsample.1.running_mean, layer1.0.downsample.1.running_var, layer1.0.downsample.1.num_batches_tracked, layer1.1.conv3.weight, layer1.1.bn3.weight, layer1.1.bn3.bias, layer1.1.bn3.running_mean, layer1.1.bn3.running_var, layer1.1.bn3.num_batches_tracked, layer2.2.conv1.weight, layer2.2.bn1.weight, layer2.2.bn1.bias, layer2.2.bn1.running_mean, layer2.2.bn1.running_var, layer2.2.bn1.num_batches_tracked, layer2.2.conv2.weight, layer2.2.bn2.weight, layer2.2.bn2.bias, layer2.2.bn2.running_mean, layer2.2.bn2.running_var, layer2.2.bn2.num_batches_tracked, layer2.2.conv3.weight, layer2.2.bn3.weight, layer2.2.bn3.bias, layer2.2.bn3.running_mean, layer2.2.bn3.running_var, layer2.2.bn3.num_batches_tracked, layer2.3.conv1.weight, layer2.3.bn1.weight, layer2.3.bn1.bias, layer2.3.bn1.running_mean, layer2.3.bn1.running_var, layer2.3.bn1.num_batches_tracked, layer2.3.conv2.weight, layer2.3.bn2.weight, layer2.3.bn2.bias, layer2.3.bn2.running_mean, layer2.3.bn2.running_var, layer2.3.bn2.num_batches_tracked, layer2.3.conv3.weight, layer2.3.bn3.weight, layer2.3.bn3.bias, layer2.3.bn3.running_mean, layer2.3.bn3.running_var, layer2.3.bn3.num_batches_tracked, layer2.0.conv3.weight, layer2.0.bn3.weight, layer2.0.bn3.bias, layer2.0.bn3.running_mean, layer2.0.bn3.running_var, layer2.0.bn3.num_batches_tracked, layer2.1.conv3.weight, layer2.1.bn3.weight, layer2.1.bn3.bias, layer2.1.bn3.running_mean, layer2.1.bn3.running_var, layer2.1.bn3.num_batches_tracked, layer3.2.conv1.weight, layer3.2.bn1.weight, layer3.2.bn1.bias, layer3.2.bn1.running_mean, layer3.2.bn1.running_var, layer3.2.bn1.num_batches_tracked, layer3.2.conv2.weight, layer3.2.bn2.weight, layer3.2.bn2.bias, layer3.2.bn2.running_mean, layer3.2.bn2.running_var, layer3.2.bn2.num_batches_tracked, layer3.2.conv3.weight, layer3.2.bn3.weight, layer3.2.bn3.bias, layer3.2.bn3.running_mean, layer3.2.bn3.running_var, layer3.2.bn3.num_batches_tracked, layer3.3.conv1.weight, layer3.3.bn1.weight, layer3.3.bn1.bias, layer3.3.bn1.running_mean, layer3.3.bn1.running_var, layer3.3.bn1.num_batches_tracked, layer3.3.conv2.weight, layer3.3.bn2.weight, layer3.3.bn2.bias, layer3.3.bn2.running_mean, layer3.3.bn2.running_var, layer3.3.bn2.num_batches_tracked, layer3.3.conv3.weight, layer3.3.bn3.weight, layer3.3.bn3.bias, layer3.3.bn3.running_mean, layer3.3.bn3.running_var, layer3.3.bn3.num_batches_tracked, layer3.4.conv1.weight, layer3.4.bn1.weight, layer3.4.bn1.bias, layer3.4.bn1.running_mean, layer3.4.bn1.running_var, layer3.4.bn1.num_batches_tracked, layer3.4.conv2.weight, layer3.4.bn2.weight, layer3.4.bn2.bias, layer3.4.bn2.running_mean, layer3.4.bn2.running_var, layer3.4.bn2.num_batches_tracked, layer3.4.conv3.weight, layer3.4.bn3.weight, layer3.4.bn3.bias, layer3.4.bn3.running_mean, layer3.4.bn3.running_var, layer3.4.bn3.num_batches_tracked, layer3.5.conv1.weight, layer3.5.bn1.weight, layer3.5.bn1.bias, layer3.5.bn1.running_mean, layer3.5.bn1.running_var, layer3.5.bn1.num_batches_tracked, layer3.5.conv2.weight, layer3.5.bn2.weight, layer3.5.bn2.bias, layer3.5.bn2.running_mean, layer3.5.bn2.running_var, layer3.5.bn2.num_batches_tracked, layer3.5.conv3.weight, layer3.5.bn3.weight, layer3.5.bn3.bias, layer3.5.bn3.running_mean, layer3.5.bn3.running_var, layer3.5.bn3.num_batches_tracked, layer3.0.conv3.weight, layer3.0.bn3.weight, layer3.0.bn3.bias, layer3.0.bn3.running_mean, layer3.0.bn3.running_var, layer3.0.bn3.num_batches_tracked, layer3.1.conv3.weight, layer3.1.bn3.weight, layer3.1.bn3.bias, layer3.1.bn3.running_mean, layer3.1.bn3.running_var, layer3.1.bn3.num_batches_tracked, layer4.2.conv1.weight, layer4.2.bn1.weight, layer4.2.bn1.bias, layer4.2.bn1.running_mean, layer4.2.bn1.running_var, layer4.2.bn1.num_batches_tracked, layer4.2.conv2.weight, layer4.2.bn2.weight, layer4.2.bn2.bias, layer4.2.bn2.running_mean, layer4.2.bn2.running_var, layer4.2.bn2.num_batches_tracked, layer4.2.conv3.weight, layer4.2.bn3.weight, layer4.2.bn3.bias, layer4.2.bn3.running_mean, layer4.2.bn3.running_var, layer4.2.bn3.num_batches_tracked, layer4.0.conv3.weight, layer4.0.bn3.weight, layer4.0.bn3.bias, layer4.0.bn3.running_mean, layer4.0.bn3.running_var, layer4.0.bn3.num_batches_tracked, layer4.1.conv3.weight, layer4.1.bn3.weight, layer4.1.bn3.bias, layer4.1.bn3.running_mean, layer4.1.bn3.running_var, layer4.1.bn3.num_batches_tracked\n",
      "\n",
      "missing keys in source state_dict: conv1.weight, bn1.weight, bn1.bias, bn1.running_mean, bn1.running_var\n",
      "\n",
      "2022-11-19 11:20:38,263 - mmcv - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      "2022-11-19 11:20:38,282 - mmcv - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      "2022-11-19 11:20:38,284 - mmcv - INFO - \n",
      "backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,285 - mmcv - INFO - \n",
      "backbone.bn1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,286 - mmcv - INFO - \n",
      "backbone.bn1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,287 - mmcv - INFO - \n",
      "backbone.layer1.0.conv1.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,288 - mmcv - INFO - \n",
      "backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,288 - mmcv - INFO - \n",
      "backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,290 - mmcv - INFO - \n",
      "backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,290 - mmcv - INFO - \n",
      "backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,291 - mmcv - INFO - \n",
      "backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,292 - mmcv - INFO - \n",
      "backbone.layer1.1.conv1.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,293 - mmcv - INFO - \n",
      "backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,293 - mmcv - INFO - \n",
      "backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,294 - mmcv - INFO - \n",
      "backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,294 - mmcv - INFO - \n",
      "backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,295 - mmcv - INFO - \n",
      "backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,296 - mmcv - INFO - \n",
      "backbone.layer2.0.conv1.weight - torch.Size([128, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,296 - mmcv - INFO - \n",
      "backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,298 - mmcv - INFO - \n",
      "backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,299 - mmcv - INFO - \n",
      "backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,300 - mmcv - INFO - \n",
      "backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,301 - mmcv - INFO - \n",
      "backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,301 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.0.weight - torch.Size([128, 64, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,302 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,303 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,304 - mmcv - INFO - \n",
      "backbone.layer2.1.conv1.weight - torch.Size([128, 128, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,305 - mmcv - INFO - \n",
      "backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,306 - mmcv - INFO - \n",
      "backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,306 - mmcv - INFO - \n",
      "backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,307 - mmcv - INFO - \n",
      "backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,308 - mmcv - INFO - \n",
      "backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,310 - mmcv - INFO - \n",
      "backbone.layer3.0.conv1.weight - torch.Size([256, 128, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,311 - mmcv - INFO - \n",
      "backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,311 - mmcv - INFO - \n",
      "backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,312 - mmcv - INFO - \n",
      "backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,313 - mmcv - INFO - \n",
      "backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,314 - mmcv - INFO - \n",
      "backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,314 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,315 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,316 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,317 - mmcv - INFO - \n",
      "backbone.layer3.1.conv1.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,318 - mmcv - INFO - \n",
      "backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,320 - mmcv - INFO - \n",
      "backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,321 - mmcv - INFO - \n",
      "backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,322 - mmcv - INFO - \n",
      "backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,322 - mmcv - INFO - \n",
      "backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,324 - mmcv - INFO - \n",
      "backbone.layer4.0.conv1.weight - torch.Size([512, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,324 - mmcv - INFO - \n",
      "backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,325 - mmcv - INFO - \n",
      "backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,327 - mmcv - INFO - \n",
      "backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,327 - mmcv - INFO - \n",
      "backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,328 - mmcv - INFO - \n",
      "backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,328 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,329 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.1.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,330 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.1.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,330 - mmcv - INFO - \n",
      "backbone.layer4.1.conv1.weight - torch.Size([512, 512, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,331 - mmcv - INFO - \n",
      "backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,331 - mmcv - INFO - \n",
      "backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,332 - mmcv - INFO - \n",
      "backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,332 - mmcv - INFO - \n",
      "backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,333 - mmcv - INFO - \n",
      "backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from open-mmlab://resnet50_v1c \n",
      " \n",
      "2022-11-19 11:20:38,333 - mmcv - INFO - \n",
      "decode_head.conv_seg.weight - torch.Size([2, 128, 1, 1]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2022-11-19 11:20:38,334 - mmcv - INFO - \n",
      "decode_head.conv_seg.bias - torch.Size([2]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2022-11-19 11:20:38,334 - mmcv - INFO - \n",
      "decode_head.convs.0.conv.weight - torch.Size([128, 512, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,335 - mmcv - INFO - \n",
      "decode_head.convs.0.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,335 - mmcv - INFO - \n",
      "decode_head.convs.0.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,336 - mmcv - INFO - \n",
      "decode_head.convs.1.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,337 - mmcv - INFO - \n",
      "decode_head.convs.1.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,337 - mmcv - INFO - \n",
      "decode_head.convs.1.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,338 - mmcv - INFO - \n",
      "decode_head.conv_cat.conv.weight - torch.Size([128, 640, 3, 3]): \n",
      "Initialized by user-defined `init_weights` in ConvModule  \n",
      " \n",
      "2022-11-19 11:20:38,339 - mmcv - INFO - \n",
      "decode_head.conv_cat.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,340 - mmcv - INFO - \n",
      "decode_head.conv_cat.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,341 - mmcv - INFO - \n",
      "auxiliary_head.conv_seg.weight - torch.Size([2, 64, 1, 1]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2022-11-19 11:20:38,341 - mmcv - INFO - \n",
      "auxiliary_head.conv_seg.bias - torch.Size([2]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2022-11-19 11:20:38,342 - mmcv - INFO - \n",
      "auxiliary_head.convs.0.conv.weight - torch.Size([64, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,343 - mmcv - INFO - \n",
      "auxiliary_head.convs.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,346 - mmcv - INFO - \n",
      "auxiliary_head.convs.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of EncoderDecoder  \n",
      " \n",
      "2022-11-19 11:20:38,372 - mmseg - INFO - Loaded 0 images\n"
     ]
    }
   ],
   "source": [
    "from mmcv.utils import Config\n",
    "from mmseg.apis import train_segmentor\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.datasets import build_dataset, build_dataloader\n",
    "from mmseg.utils import build_dp, setup_multi_processes\n",
    "\n",
    "config = r'configs/fcn/fcn_r18b-d8_512x1024_20k_chestxray.py'\n",
    "\n",
    "\n",
    "\n",
    "cfg = Config.fromfile(config)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.seed = 255\n",
    "\n",
    "setup_multi_processes(cfg)\n",
    "\n",
    "model = build_segmentor(\n",
    "    cfg.model,\n",
    "    train_cfg=cfg.get('train_cfg'),\n",
    "    test_cfg=cfg.get('test_cfg'))\n",
    "model.init_weights()\n",
    "\n",
    "dataset = [build_dataset(cfg.data.train)]\n",
    "\n",
    "distributed = False\n",
    "validate = True\n",
    "#train_segmentor(\n",
    "#    model,\n",
    "#    datasets,\n",
    "#    cfg,\n",
    "#    distributed=False,\n",
    "#    validate=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<mmseg.datasets.lungseg.LungSegmentationDataset at 0x7f6a9c8540d0>],\n",
       " {'num_gpus': 1,\n",
       "  'dist': False,\n",
       "  'seed': 255,\n",
       "  'drop_last': True,\n",
       "  'samples_per_gpu': 2,\n",
       "  'workers_per_gpu': 2})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# The default loader config\n",
    "loader_cfg = dict(\n",
    "    # cfg.gpus will be ignored if distributed\n",
    "    num_gpus=len(cfg.gpu_ids),\n",
    "    dist=distributed,\n",
    "    seed=cfg.seed,\n",
    "    drop_last=True)\n",
    "# The overall dataloader settings\n",
    "loader_cfg.update({\n",
    "    k: v\n",
    "    for k, v in cfg.data.items() if k not in [\n",
    "        'train', 'val', 'test', 'train_dataloader', 'val_dataloader',\n",
    "        'test_dataloader'\n",
    "    ]\n",
    "})\n",
    "# The specific dataloader settings\n",
    "train_loader_cfg = {**loader_cfg, **cfg.data.get('train_dataloader', {})}\n",
    "dataset, train_loader_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'mmseg.datasets.lungseg.LungSegmentationDataset'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m dl \u001b[39m=\u001b[39m DataLoader(dataset)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(dl))\n\u001b[0;32m----> 5\u001b[0m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(dl))\n",
      "File \u001b[0;32m~/miniconda3/envs/open-mmseg/lib/python3.8/site-packages/torch/utils/data/dataloader.py:517\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    516\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 517\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    518\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    520\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    521\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/open-mmseg/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    556\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    559\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-mmseg/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:47\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 47\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-mmseg/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:85\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m     transposed \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)\n\u001b[1;32m     83\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[0;32m---> 85\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'mmseg.datasets.lungseg.LungSegmentationDataset'>"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "\n",
    "dl = DataLoader(dataset)\n",
    "print(len(dl))\n",
    "next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_loaders \u001b[39m=\u001b[39m [build_dataloader(ds, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrain_loader_cfg) \u001b[39mfor\u001b[39;00m ds \u001b[39min\u001b[39;00m dataset]\n",
      "Cell \u001b[0;32mIn [19], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_loaders \u001b[39m=\u001b[39m [build_dataloader(ds, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrain_loader_cfg) \u001b[39mfor\u001b[39;00m ds \u001b[39min\u001b[39;00m dataset]\n",
      "File \u001b[0;32m/media/erick/0123-4567/Github/mmlab/mmsegmentation/mmsegmentation/mmseg/datasets/builder.py:153\u001b[0m, in \u001b[0;36mbuild_dataloader\u001b[0;34m(dataset, samples_per_gpu, workers_per_gpu, num_gpus, dist, shuffle, seed, drop_last, pin_memory, persistent_workers, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m init_fn \u001b[39m=\u001b[39m partial(\n\u001b[1;32m    149\u001b[0m     worker_init_fn, num_workers\u001b[39m=\u001b[39mnum_workers, rank\u001b[39m=\u001b[39mrank,\n\u001b[1;32m    150\u001b[0m     seed\u001b[39m=\u001b[39mseed) \u001b[39mif\u001b[39;00m seed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39mif\u001b[39;00m digit_version(torch\u001b[39m.\u001b[39m__version__) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m digit_version(\u001b[39m'\u001b[39m\u001b[39m1.8.0\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 153\u001b[0m     data_loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m    154\u001b[0m         dataset,\n\u001b[1;32m    155\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    156\u001b[0m         sampler\u001b[39m=\u001b[39;49msampler,\n\u001b[1;32m    157\u001b[0m         num_workers\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[1;32m    158\u001b[0m         collate_fn\u001b[39m=\u001b[39;49mpartial(collate, samples_per_gpu\u001b[39m=\u001b[39;49msamples_per_gpu),\n\u001b[1;32m    159\u001b[0m         pin_memory\u001b[39m=\u001b[39;49mpin_memory,\n\u001b[1;32m    160\u001b[0m         shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m    161\u001b[0m         worker_init_fn\u001b[39m=\u001b[39;49minit_fn,\n\u001b[1;32m    162\u001b[0m         drop_last\u001b[39m=\u001b[39;49mdrop_last,\n\u001b[1;32m    163\u001b[0m         persistent_workers\u001b[39m=\u001b[39;49mpersistent_workers,\n\u001b[1;32m    164\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     data_loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m    167\u001b[0m         dataset,\n\u001b[1;32m    168\u001b[0m         batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m         drop_last\u001b[39m=\u001b[39mdrop_last,\n\u001b[1;32m    176\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-mmseg/lib/python3.8/site-packages/torch/utils/data/dataloader.py:266\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# map-style\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     \u001b[39mif\u001b[39;00m shuffle:\n\u001b[1;32m    264\u001b[0m         \u001b[39m# Cannot statically verify that dataset is Sized\u001b[39;00m\n\u001b[1;32m    265\u001b[0m         \u001b[39m# Somewhat related: see NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m         sampler \u001b[39m=\u001b[39m RandomSampler(dataset, generator\u001b[39m=\u001b[39;49mgenerator)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m         sampler \u001b[39m=\u001b[39m SequentialSampler(dataset)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-mmseg/lib/python3.8/site-packages/torch/utils/data/sampler.py:103\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWith replacement=False, num_samples should not be specified, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39msince a random permute will be performed.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    102\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnum_samples should be a positive integer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mvalue, but got num_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples))\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "data_loaders = [build_dataloader(ds, **train_loader_cfg) for ds in dataset] # build PyTorch data loader\n",
    "data_loaders = [build_dataloader(dataset, **train_loader_cfg)] # build PyTorch data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.13 ('open-mmseg')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n open-mmseg ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "next(data_loaders[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('open-mmseg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f8261b55a83317e03287f12cbc5aa6509cc2497c1e5ef5baac73372f5ccca04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
